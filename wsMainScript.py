import osimport pandas as pdimport numpy as npfrom datetime import datetime, timedelta, dateimport requestsfrom scipy.stats import pearsonr, ttest_indfrom math import radians, sin, cos, sqrt, atan2import matplotlib.pyplot as pltimport seaborn as sns# ===========================# USER INPUT# ===========================event_name = input("Enter hurricane/event name: ").strip()try:    min_lat = float(input("Min latitude (e.g., 33): "))    max_lat = float(input("Max latitude (e.g., 45): "))    min_lon = float(input("Min longitude (e.g., -85): "))    max_lon = float(input("Max longitude (e.g., -70): "))    start_date_str = input("Start date (YYYY-MM-DD): ").strip()    end_date_str = input("End date (YYYY-MM-DD): ").strip()    start_date = datetime.strptime(start_date_str, "%Y-%m-%d").date()    end_date = datetime.strptime(end_date_str, "%Y-%m-%d").date()    variable = input("Variable (TMAX, TMIN, PRCP, TAVG): ").strip().upper()except Exception as e:    print(f"Invalid input: {e}")    exit()# ===========================# FILES AND PATHS# ===========================station_file = 'ghcnd-stations.txt'inventory_file = 'ghcnd-inventory.txt'dly_folder = 'dly_files'os.makedirs(dly_folder, exist_ok=True)# ===========================# LOAD INVENTORY AND FILTER# ===========================inventory = pd.read_csv(inventory_file, delim_whitespace=True, header=None,                        names=["ID","LAT","LON","ELEMENT","FIRSTYEAR","LASTYEAR"])inventory['ID'] = inventory['ID'].astype(str).str.strip()inv_filtered = inventory[    (inventory['ELEMENT']==variable) &    (inventory['FIRSTYEAR']<=start_date.year) &    (inventory['LASTYEAR']>=end_date.year)]# ===========================# LOAD STATION DATA# ===========================station_data = []with open(station_file,'r') as f:    for line in f:        station_id = line[0:11].strip()        lat = float(line[12:20].strip())        lon = float(line[21:30].strip())        name = line[41:71].strip()        if min_lat <= lat <= max_lat and min_lon <= lon <= max_lon:            station_data.append((station_id, lat, lon, name))station_df = pd.DataFrame(station_data, columns=["ID","LAT","LON","NAME"])station_df['ID'] = station_df['ID'].astype(str).str.strip()stations = pd.merge(station_df, inv_filtered[['ID']], on='ID', how='inner')# ===========================# DOWNLOAD .DLY FILES# ===========================base_url = "https://www.ncei.noaa.gov/pub/data/ghcn/daily/all"for station_id in stations['ID'].unique():    dest = os.path.join(dly_folder,f"{station_id}.dly")    if not os.path.exists(dest):        try:            r = requests.get(f"{base_url}/{station_id}.dly")            if r.status_code == 200:                with open(dest,'wb') as f: f.write(r.content)        except: continue# ===========================# PARSE DLY FILE# ===========================def parse_dly(filepath, variable, start_date, end_date):    days_dict = {}    try:        with open(filepath,'r') as f:            for line in f:                if line[17:21]==variable:                    year = int(line[11:15])                    month = int(line[15:17])                    for i in range(31):                        val_str = line[21+i*8:26+i*8]                        try:                            val = int(val_str)                            day = i+1                            d = date(year,month,day)                            if start_date <= d <= end_date and val != -9999:                                days_dict[d] = 1                        except: continue    except: pass    return days_dict# ===========================# GENERATE DATE LIST# ===========================date_list=[]cur_date=start_datewhile cur_date <= end_date:    date_list.append(cur_date)    cur_date += timedelta(days=1)# ===========================# CALCULATE % MISSING PER STATION# ===========================station_missing = []daily_missing_counts = np.zeros(len(date_list))daily_total_counts = np.zeros(len(date_list))for station_id in stations['ID'].unique():    path = os.path.join(dly_folder,f"{station_id}.dly")    if os.path.exists(path):        vals = parse_dly(path, variable, start_date, end_date)        total_days = len(date_list)        missing_days = total_days - len(vals)        station_info = stations[stations['ID']==station_id].iloc[0]        station_missing.append({            'ID': station_id,            'LAT': station_info['LAT'],            'LON': station_info['LON'],            'NAME': station_info['NAME'],            'Missing %': round((missing_days/total_days)*100,2)        })        # Daily counts for time series        for i, d in enumerate(date_list):            daily_total_counts[i] += 1            if d not in vals:                daily_missing_counts[i] += 1missing_df = pd.DataFrame(station_missing)# ===========================# COASTAL VS INLAND# ===========================COAST_DISTANCE_KM = 50coast_points = [    (29.6, -95.0), (30.3, -81.4), (40.7, -74.0), (25.8, -80.1)]def haversine(lat1, lon1, lat2, lon2):    R = 6371    dlat = radians(lat2-lat1)    dlon = radians(lon2-lon1)    a = sin(dlat/2)**2 + cos(radians(lat1))*cos(radians(lat2))*sin(dlon/2)**2    return 2*R*atan2(sqrt(a), sqrt(1-a))def min_dist_to_coast(lat, lon):    return min(haversine(lat, lon, c_lat, c_lon) for c_lat,c_lon in coast_points)missing_df['Distance_to_Coast_km'] = missing_df.apply(lambda r: min_dist_to_coast(r['LAT'], r['LON']), axis=1)missing_df['Region'] = missing_df['Distance_to_Coast_km'].apply(lambda d: 'Coastal' if d<=COAST_DISTANCE_KM else 'Inland')# ===========================# STATISTICAL COMPARISONS# ===========================coastal = missing_df[missing_df['Region']=='Coastal']['Missing %']inland = missing_df[missing_df['Region']=='Inland']['Missing %']t_stat, p_val = ttest_ind(coastal, inland, equal_var=False)lat_corr, lat_p = pearsonr(missing_df['LAT'], missing_df['Missing %'])lon_corr, lon_p = pearsonr(missing_df['LON'], missing_df['Missing %'])print(f"\n--- Statistical Summary for {event_name} ---")print(f"Coastal mean missing %: {coastal.mean():.2f}")print(f"Inland mean missing %:  {inland.mean():.2f}")print(f"T-test: t={t_stat:.3f}, p={p_val:.4f}")print(f"Latitude vs % Missing: r={lat_corr:.3f}, p={lat_p:.4f}")print(f"Longitude vs % Missing: r={lon_corr:.3f}, p={lon_p:.4f}")# ===========================# PLOT STATISTICAL COMPARISONS# ===========================sns.set(style="whitegrid")# 1. Coastal vs Inlandplt.figure(figsize=(6,5))sns.barplot(x='Region', y='Missing %', data=missing_df, ci='sd', palette=['skyblue','salmon'])plt.title(f'Coastal vs Inland Station Reliability\n{event_name}')plt.ylabel('Mean % Missing')plt.ylim(0,100)plt.tight_layout()plt.show()# 2. Latitude vs % Missingplt.figure(figsize=(7,5))sns.regplot(x='LAT', y='Missing %', data=missing_df, scatter_kws={'color':'darkblue'}, line_kws={'color':'red'})plt.title(f'Latitude vs % Missing\n{event_name}')plt.xlabel('Latitude')plt.ylabel('% Missing')plt.ylim(0,100)plt.tight_layout()plt.show()# 3. Longitude vs % Missingplt.figure(figsize=(7,5))sns.regplot(x='LON', y='Missing %', data=missing_df, scatter_kws={'color':'darkgreen'}, line_kws={'color':'red'})plt.title(f'Longitude vs % Missing\n{event_name}')plt.xlabel('Longitude')plt.ylabel('% Missing')plt.ylim(0,100)plt.tight_layout()plt.show()# 4. Daily % Missing Time Seriesdaily_percent_missing = (daily_missing_counts/daily_total_counts)*100plt.figure(figsize=(12,5))plt.plot(date_list, daily_percent_missing, marker='o', color='darkred')plt.title(f'Daily % Missing Stations During {event_name}')plt.xlabel('Date')plt.ylabel('% Missing')plt.xticks(rotation=45)plt.ylim(0,100)plt.grid(True)plt.tight_layout()plt.show()# ===========================# SAVE OUTPUTS# ===========================missing_df.to_csv(f'stations_missing_{event_name}_{variable}_{start_date_str}_to_{end_date_str}.csv', index=False)print(f"Saved missing station data to CSV for {event_name}.")